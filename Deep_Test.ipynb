{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import PYCLASS2_air_Copy1\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PYCLASS2_air_test\n",
    "import CNN_CLASS\n",
    "import librosa\n",
    "import CNN_CLASS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYCLASS IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature2(file_name):\n",
    "    \n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)       \n",
    "    ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "    \n",
    "    return ext_features\n",
    "    \n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = extract_feature2('/home/libedev/mute/mute-hero/air_save/test/Sound_1568942798303_Sound_1568942496705_AAR8914.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.88405090e+02,  1.90324203e+02,  1.24346628e+01,  2.81224575e+01,\n",
       "        1.21302862e+01,  1.31172152e+01,  1.57276831e+01,  7.11120462e+00,\n",
       "        5.57665777e+00,  4.90023470e+00,  6.90760612e+00,  7.76630592e+00,\n",
       "        3.62765193e+00,  1.28564763e+00,  4.88286877e+00,  1.37390649e+00,\n",
       "        2.86038184e+00,  4.89184380e+00,  4.05804682e+00,  2.13125634e+00,\n",
       "        1.19056380e+00,  2.42960525e+00,  1.35449135e+00,  8.87673497e-01,\n",
       "       -1.28212357e+00, -2.93305963e-01,  3.43652427e-01,  3.69932830e-01,\n",
       "        1.40020049e+00,  1.60742712e+00,  1.14690220e+00,  1.03424323e+00,\n",
       "        1.36497974e+00,  7.00596094e-01,  2.46192813e+00,  1.70928776e+00,\n",
       "        8.52274954e-01,  6.97185814e-01, -6.34750605e-01,  2.05308616e-01,\n",
       "        8.91763985e-01,  8.47656310e-01,  8.20408821e-01,  8.02219272e-01,\n",
       "        6.95855856e-01,  8.16423953e-01,  9.27952051e-01,  8.23313773e-01,\n",
       "        7.69696176e-01,  8.06571662e-01,  7.88145721e-01,  8.32913935e-01,\n",
       "        8.40859532e-01,  5.58647423e+01,  2.83886623e+01,  5.51973760e-01,\n",
       "        6.21245444e-01,  7.48915970e-01,  2.79363346e+00,  4.93293911e-01,\n",
       "        2.58130819e-01,  3.01261038e-01,  2.73443311e-01,  2.90484697e-01,\n",
       "        1.82354793e-01,  1.85036615e-01,  2.18807995e-01,  2.25761965e-01,\n",
       "        2.10061029e-01,  1.41833141e-01,  1.04993559e-01,  1.14232749e-01,\n",
       "        1.26368240e-01,  1.26317188e-01,  1.08646564e-01,  6.39925003e-02,\n",
       "        6.62389696e-02,  6.45180047e-02,  5.39421663e-02,  4.49520014e-02,\n",
       "        4.08838280e-02,  4.19733264e-02,  2.89321747e-02,  2.38033552e-02,\n",
       "        2.37037539e-02,  2.12760884e-02,  2.79303938e-02,  2.46981233e-02,\n",
       "        1.98850483e-02,  1.62635297e-02,  1.19746486e-02,  1.38004664e-02,\n",
       "        1.46265076e-02,  1.72636751e-02,  2.22436730e-02,  1.87821165e-02,\n",
       "        2.11547352e-02,  2.13014726e-02,  2.34144311e-02,  2.17718929e-02,\n",
       "        1.86005477e-02,  1.51733076e-02,  1.07779875e-02,  8.01551994e-03,\n",
       "        5.28365327e-03,  6.11213967e-03,  7.89383892e-03,  4.36410587e-03,\n",
       "        3.38784838e-03,  2.66102469e-03,  2.99840677e-03,  2.15210114e-03,\n",
       "        1.52039691e-03,  1.33895117e-03,  1.05016120e-03,  8.44697177e-04,\n",
       "        8.58876796e-04,  6.94396091e-04,  6.92407892e-04,  7.19726086e-04,\n",
       "        7.65372475e-04,  8.28014570e-04,  1.09654176e-03,  1.35014427e-03,\n",
       "        1.11667777e-03,  8.39452608e-04,  8.68846488e-04,  6.95632945e-04,\n",
       "        6.31338626e-04,  6.22085121e-04,  4.92813007e-04,  4.42483521e-04,\n",
       "        4.50922351e-04,  3.67052358e-04,  2.63602298e-04,  2.45824456e-04,\n",
       "        4.01882717e-04,  2.90513388e-04,  2.13237028e-04,  2.19289839e-04,\n",
       "        2.28758581e-04,  3.02098400e-04,  4.55652567e-04,  2.70161981e-04,\n",
       "        1.72342581e-04,  1.59612347e-04,  1.54378489e-04,  2.29897938e-04,\n",
       "        1.27139720e-04,  6.14370365e-05,  5.99100786e-05,  4.63398355e-05,\n",
       "        3.24353387e-05,  3.05377216e-05,  4.44646503e-05,  3.27803973e-05,\n",
       "        2.35006137e-05,  1.62002088e-05,  1.28256452e-05,  1.13170854e-05,\n",
       "        1.17257123e-05,  1.10639739e-05,  1.01186833e-05,  7.96231416e-06,\n",
       "        6.10793222e-06,  4.01330362e-06,  1.09955954e-06,  7.75949971e-08,\n",
       "        4.98090902e-10,  2.26752523e-11,  2.10583061e-11,  1.97760974e-11,\n",
       "        1.87019913e-11,  1.78032589e-11,  1.70412798e-11,  1.64272294e-11,\n",
       "        1.59344395e-11,  1.55450340e-11,  1.52730953e-11,  1.50900386e-11,\n",
       "        2.31888590e+01,  1.29436260e+01,  1.45666544e+01,  1.54528996e+01,\n",
       "        1.64619126e+01,  1.83926993e+01,  5.26175475e+01,  1.04890273e-03,\n",
       "       -4.38786258e-02,  3.28305000e-01, -6.25897746e-02, -6.23139064e-02,\n",
       "       -4.36315152e-02])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = s_data\n",
    "x=np.array([0,0,0,0,0,0,0])\n",
    "train_data = np.zeros((1,200))\n",
    "train_data =  np.concatenate((train_data2,x),axis=None)\n",
    "train_data = train_data.reshape(1,1,10,20)\n",
    "dtype = torch.FloatTensor\n",
    "train_data  = torch.as_tensor(train_data).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 20])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = '/home/libedev/mute/mute-hero/download/dataset/model2/'\n",
    "PATH  = save_path + 'model3.pkl'\n",
    "model = CNN_CLASS2.CNN2()\n",
    "model.load_state_dict(torch.load(PATH)) #gpu 에서 gpu로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10, 20])\n"
     ]
    }
   ],
   "source": [
    "out = model(train_data)\n",
    "#print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2])\n",
      "비행소리 입니다.\n"
     ]
    }
   ],
   "source": [
    " _, predicted = torch.max(out.data, 1)\n",
    "print(predicted)\n",
    "if predicted[0] == 1:\n",
    "    print(\"자동차 경적소리 및 이외의 소리 입니다.\")\n",
    "elif predicted[0] ==2 :\n",
    "    print(\"비행소리 입니다.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_13.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_12.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_11.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_20.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_24.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/Sound_1590729409597_train_airplane_12.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_2.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_22.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_6.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_14.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_21.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_3.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_15.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_16.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_28.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_30.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_10.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_1.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_19.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_17.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_29.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_7.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_25.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_26.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_23.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_9.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_4.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_27.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_8.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_5.wav\n",
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/test_18.wav\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/libedev/mute/mute-hero/download/dataset/model2/model2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-7e6c15c686ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-7e6c15c686ef>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mPATH\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model2.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_CLASS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNN2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/libedev/mute/mute-hero/download/dataset/model2/model2.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def predict(file_name):\n",
    "    \n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)       \n",
    "    ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "    \n",
    "    s_data = ext_features\n",
    "\n",
    "\n",
    "    train_data2 = s_data\n",
    "    x=np.array([0,0,0,0,0,0,0])\n",
    "    train_data = np.zeros((1,200))\n",
    "    train_data =  np.concatenate((train_data2,x),axis=None)\n",
    "    train_data = train_data.reshape(1,1,10,20)\n",
    "    dtype = torch.FloatTensor\n",
    "    train_data  = torch.as_tensor(train_data).type(dtype)\n",
    "\n",
    "    \n",
    "    save_path = '/home/libedev/mute/mute-hero/download/dataset/model2/'\n",
    "    PATH  = save_path + 'model2.pkl'\n",
    "    model = CNN_CLASS.CNN2()\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    out = model(train_data)\n",
    "\n",
    "\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "\n",
    "    if predicted[0] == 1:\n",
    "        \n",
    "        result = 1\n",
    "    \n",
    "    elif predicted[0] ==2 :\n",
    "        \n",
    "        result = 2\n",
    "        \n",
    "    return result\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    file = '/home/libedev/mute/mute-hero/air_save/test/'\n",
    "    \n",
    "    for i in os.listdir(str(file)):\n",
    "    \n",
    "    \n",
    "        if os.path.isfile(str(file)+str(i)):\n",
    "            \n",
    "            print(\"yes\")\n",
    "            \n",
    "            file_name = str(file)+str(i)\n",
    "            print(file_name)\n",
    "            \n",
    "            \n",
    "            \n",
    "    predict(file_name)\n",
    "\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/libedev/mute/mute-hero/air_save/test/'\n",
    "\n",
    "if os.path.isfile(file):\n",
    "    \n",
    "    print(\"Yes. it is a file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "/home/libedev/mute/mute-hero/air_save/test/Sound_1586161128025_sample10-18.wav\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(str(file)):\n",
    "    #print(i)\n",
    "    \n",
    "    if os.path.isfile(str(file)+str(i)):\n",
    "        print(\"yes\")\n",
    "        print(str(file)+str(i))\n",
    "    else:\n",
    "        print(\"No File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (64x1x6). Calculated output size: (64x0x3). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b90a62c03ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mute/mute-hero/NEW_Data_preprocessing/Sound_deeplearning/Sound_deeplearning2/CNN_CLASS.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    140\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 539\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (64x1x6). Calculated output size: (64x0x3). Output size is too small"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import PYCLASS2_air_Copy1\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PYCLASS2_air_test\n",
    "import CNN_CLASS\n",
    "import librosa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def predict(file_name):\n",
    "    \n",
    "    # wav 파일을 딥러닝 모델에 판별하기 위해 전저리 하는 코드 ( wav ---> n*n 배열로 바뀜 )\n",
    "    \n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)       \n",
    "    ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "    \n",
    "    s_data = ext_features\n",
    "    train_data2 = s_data\n",
    "    x=np.array([0,0,0,0,0,0,0])\n",
    "    train_data = np.zeros((1,200))\n",
    "    train_data =  np.concatenate((train_data2,x),axis=None)\n",
    "    train_data = train_data.reshape(1,1,10,20)\n",
    "    dtype = torch.FloatTensor\n",
    "    train_data  = torch.as_tensor(train_data).type(dtype)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    return train_data\n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "     # 학습시켰던 모델 로딩\n",
    "    save_path = '/home/libedev/mute/mute-hero/download/dataset/model2/'\n",
    "    PATH  = save_path + 'model2.pkl'\n",
    "    model = CNN_CLASS.CNN2()\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    \n",
    "    #업로드된 파일이 있는 폴더를 보면서 파일이 있으면 위 방식처럼 진행하여 비행소음인지 판별\n",
    "    \n",
    "    file = '/home/libedev/mute/mute-hero/air_save/TEST2/'\n",
    "    \n",
    "    for i in os.listdir(str(file)):\n",
    "        \n",
    "        if os.path.isfile(str(file)+str(i)):\n",
    "            file_name = str(file)+str(i)\n",
    "            \n",
    "    \n",
    "    result=predict(file_name)\n",
    "    out = model(result)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    \n",
    "    \n",
    "    if predicted[0] == 1:\n",
    "        \n",
    "        print(\"not airplane\")   # 비행기 이외의 소음으로 판별되면 false반환\n",
    "    \n",
    "    elif predicted[0] ==2 :\n",
    "        \n",
    "        print(\"airplane\")    # 비행기 소음으로 판별되면 true 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MUTE",
   "language": "python",
   "name": "mute"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
